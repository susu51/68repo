<analysis>
The AI engineer's work on Kuryecini has been extensive, moving from stabilizing real-time order notifications and fixing core order placement flows to developing a sophisticated AI Diagnostics panel. Initial efforts resolved critical WebSocket disconnections, streamlined customer order creation, and implemented business order approval. The focus then shifted to the multi-phase AI Diagnostics panel, starting with backend models, ingestion endpoints, and UI shells. Development has been highly iterative, with the user providing detailed requirements and refinements, leading to the creation of an AI Settings page, a Panel AI Asistanı chat interface with streaming LLM responses, and advanced code exploration tools (grep, list, AST outline). Key issues included a Sipariş Ver button bug (double API prefix) and deployment blockers, which were addressed through refactoring database connections and cache management. The latest work involves integrating a Kuryecini Ops Co-Pilot master system prompt with structured outputs and tool calling capabilities for the AI Assistant.
</analysis>

<product_requirements>
The Kuryecini platform is a multi-role (Customer, Business, Courier, Admin) application (React, FastAPI, MongoDB) focused on seamless, real-time end-to-end order flow. Implemented features include a real-time order routing system, Admin and Business panel real-time order visibility/notifications, customer order placement, business order approval with courier task creation, and a Courier Waiting Tasks panel.

The primary new feature request is a secure, multi-app AI Diagnostics panel for the Admin Panel. It should aggregate logs, redact PII, classify errors, perform Root Cause Analysis (RCA), and propose fixes with example code patches using an LLM. This requires backend data models (, , ), ingestion API (), PII redaction, fingerprinting/clustering, and a React/Tailwind frontend UI. The AI Assistant needs to be panel-aware (customer, business, courier, multi), support time windows, preset questions, context toggles (metrics, logs), streaming markdown output, and integrate with either an Emergent LLM Key or a custom OpenAI API key. It must provide structured responses (Diagnosis, RCA, Solutions, Patch, Tests, Monitoring, DoD) and leverage advanced code exploration tools (list_files, grep, ast_outline) for context.
</product_requirements>

<key_technical_concepts>
-   **Full-stack Architecture:** React, FastAPI, MongoDB.
-   **Real-time Communication:** WebSockets (FastAPI, React hooks), SSE.
-   **AI Integration:** LLMs (OpenAI, Emergent LLM Key), PII Redaction, Error Clustering, AI-driven RCA.
-   **Frontend UI:** React Context API, React Router DOM, Tailwind CSS.
-   **Backend Framework:** FastAPI, Pydantic for data models.
-   **Database:** MongoDB (indexing, migrations, UUIDs for IDs).
-   **DevOps:** backend                          RUNNING   pid 43, uptime 0:00:02
code-server                      STOPPED   Not started
frontend                         RUNNING   pid 44, uptime 0:00:02
mongodb                          RUNNING   pid 47, uptime 0:00:02
nginx-code-proxy                 RUNNING   pid 41, uptime 0:00:02
supervisor>  for service management, Kubernetes ingress rules.
-   **Code Quality:** Structured prompts, JSON validation, retry mechanisms, code exploration tools (grep, AST).
</key_technical_concepts>

<code_architecture>

-   ****: The main FastAPI application. Continuously updated to register new routers (, , ) and manage database initialization.
-   ****: (NEW) Defines Pydantic models for AI settings (API key, redaction rules, rate limits).
-   ****: (NEW) Implements CRUD endpoints for AI settings, including an API key test. Integrated into .
-   ****: (NEW) Implements the  endpoint for the AI Assistant, handling context building, PII redaction, LLM calls, and SSE streaming. Also includes new routes , , .
-   ****: (NEW) Pydantic  for managing environment variables (DB, Redis, App Name, AI flags). Used to centralize configuration.
-   ****: (NEW) Refactored MongoDB connection to use , remove hardcoding, and add connection parameters (timeouts, appname).
-   ****: (MODIFIED) Updated to use  for Redis enabling, URL, and default TTL. Includes  for when Redis is disabled and robust JSON serialization.
-   ****: (NEW) Abstracted LLM provider logic, supporting both Emergent LLM Key and custom OpenAI API keys with fallback mechanisms.
-   ****: (NEW) Contains utility functions for advanced code exploration: , , .
-   ****: Modified to include new feature flags like , , , .
-   ****: Main frontend component. Modified to include navigation for Admin Settings and Admin Tools, integrating the new  and  components.
-   ****: (MODIFIED) Admin settings page. Now includes an Entegrasyonlar tab with a sub-navigation for AI Ayarları, rendering the  component.
-   ****: (NEW) UI component for managing AI settings, including OpenAI API key input, redaction rules, time window, rate limits, and connection status widget.
-   ****: (NEW) The core UI for the AI Assistant chat, featuring scope selection, time window, preset questions, context toggles, prompt input, streaming markdown output, and LLM metadata display.
-   ****: (MODIFIED) Fixed a critical bug where the Sipariş Ver button was sending requests to  instead of .
-   ****: (NEW) Client-side API functions for interacting with  and  endpoints.
-   ****: (NEW) Client-side API functions for interacting with the streaming  endpoint.
</code_architecture>

<pending_tasks>
-   Complete order tracking features with real-time updates and map view (PHASE 2C).
-   Integrate customer rating modal post-delivery (PHASE 2C).
-   Implement Business/Restaurant analytics (PHASE 2D).
-   Add unit and E2E tests for all new features (PHASE 2D).
-   Implement Yeni Sipariş toast + badge counter in Business Panel.
-   Implement order filters in Business Panel.
-   Implement manual refresh button + automatic WS/poll sync in Business Panel.
-   Add Observability metrics (, ) to .
-   Complete Phase 2 of AI Diagnostics: ChatGPT integration for error explanation, RCA, and patch generation.
-   Complete Phase 3 of AI Diagnostics: Admin UI for coupons.
-   Implement map-based view for courier waiting tasks.
-   Implement Accept Task button for couriers.
-   **Integrate Kuryecini Ops Co-Pilot master system prompt and tool calling for the AI Assistant.** (Current immediate next step, with 3 proposed options for integration depth).
</pending_tasks>

<current_work>
Immediately prior to this summary, the AI engineer was working on hardening the Panel AI Asistanı feature, ensuring it provides accurate, structured, and actionable Turkish responses using a real LLM (not static templates). This involved implementing a provider abstraction () to support both the Emergent LLM Key and a custom OpenAI API key, along with fallback logic and self-test endpoints. Advanced search tools (file listing, grep, AST outline) were also added to the backend for the AI Dev Panel.

A critical bug where the Sipariş Ver button on the customer panel was not working due to a double API prefix in the API call was identified and fixed. Additionally, several deployment blockers related to hardcoded MongoDB URLs and Redis caching were addressed by refactoring configuration management into a new  package and modifying database/cache utilities to be environment-driven and robust.

The most recent task involved receiving a comprehensive Master System Prompt (Kuryecini Ops Co-Pilot) for the AI Assistant from the user, detailing strict principles, context keys, answer templates, and tool interfaces. The AI engineer has reviewed this and proposed three options for its integration, ranging from full integration with tool calling to a phased or hybrid approach.
</current_work>

<optional_next_step>
Integrate the Kuryecini Ops Co-Pilot master system prompt and tool interface into the AI Assistant.
</optional_next_step>
